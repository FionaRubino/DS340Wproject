{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2762e9fa",
   "metadata": {},
   "source": [
    "# Heart Disease Prediction - Group 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6b454e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.vscode', 'dataset-numerical.csv', 'heartprediction.ipynb', 'README.md', 'venv', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "print(os.listdir())\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "407c237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"dataset-numerical.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19081c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1025, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.00000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.434146</td>\n",
       "      <td>0.695610</td>\n",
       "      <td>0.942439</td>\n",
       "      <td>131.611707</td>\n",
       "      <td>246.00000</td>\n",
       "      <td>0.149268</td>\n",
       "      <td>0.529756</td>\n",
       "      <td>149.114146</td>\n",
       "      <td>0.336585</td>\n",
       "      <td>1.071512</td>\n",
       "      <td>1.385366</td>\n",
       "      <td>0.754146</td>\n",
       "      <td>2.323902</td>\n",
       "      <td>0.513171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.072290</td>\n",
       "      <td>0.460373</td>\n",
       "      <td>1.029641</td>\n",
       "      <td>17.516718</td>\n",
       "      <td>51.59251</td>\n",
       "      <td>0.356527</td>\n",
       "      <td>0.527878</td>\n",
       "      <td>23.005724</td>\n",
       "      <td>0.472772</td>\n",
       "      <td>1.175053</td>\n",
       "      <td>0.617755</td>\n",
       "      <td>1.030798</td>\n",
       "      <td>0.620660</td>\n",
       "      <td>0.500070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          sex           cp     trestbps        chol  \\\n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.00000   \n",
       "mean     54.434146     0.695610     0.942439   131.611707   246.00000   \n",
       "std       9.072290     0.460373     1.029641    17.516718    51.59251   \n",
       "min      29.000000     0.000000     0.000000    94.000000   126.00000   \n",
       "25%      48.000000     0.000000     0.000000   120.000000   211.00000   \n",
       "50%      56.000000     1.000000     1.000000   130.000000   240.00000   \n",
       "75%      61.000000     1.000000     2.000000   140.000000   275.00000   \n",
       "max      77.000000     1.000000     3.000000   200.000000   564.00000   \n",
       "\n",
       "               fbs      restecg      thalach        exang      oldpeak  \\\n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.000000   \n",
       "mean      0.149268     0.529756   149.114146     0.336585     1.071512   \n",
       "std       0.356527     0.527878    23.005724     0.472772     1.175053   \n",
       "min       0.000000     0.000000    71.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000   132.000000     0.000000     0.000000   \n",
       "50%       0.000000     1.000000   152.000000     0.000000     0.800000   \n",
       "75%       0.000000     1.000000   166.000000     1.000000     1.800000   \n",
       "max       1.000000     2.000000   202.000000     1.000000     6.200000   \n",
       "\n",
       "             slope           ca         thal       target  \n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  \n",
       "mean      1.385366     0.754146     2.323902     0.513171  \n",
       "std       0.617755     1.030798     0.620660     0.500070  \n",
       "min       0.000000     0.000000     0.000000     0.000000  \n",
       "25%       1.000000     0.000000     2.000000     0.000000  \n",
       "50%       1.000000     0.000000     2.000000     1.000000  \n",
       "75%       2.000000     1.000000     3.000000     1.000000  \n",
       "max       2.000000     4.000000     3.000000     1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset eda\n",
    "print(dataset.shape)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1dcdc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025 entries, 0 to 1024\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1025 non-null   int64  \n",
      " 1   sex       1025 non-null   int64  \n",
      " 2   cp        1025 non-null   int64  \n",
      " 3   trestbps  1025 non-null   int64  \n",
      " 4   chol      1025 non-null   int64  \n",
      " 5   fbs       1025 non-null   int64  \n",
      " 6   restecg   1025 non-null   int64  \n",
      " 7   thalach   1025 non-null   int64  \n",
      " 8   exang     1025 non-null   int64  \n",
      " 9   oldpeak   1025 non-null   float64\n",
      " 10  slope     1025 non-null   int64  \n",
      " 11  ca        1025 non-null   int64  \n",
      " 12  thal      1025 non-null   int64  \n",
      " 13  target    1025 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 112.2 KB\n"
     ]
    }
   ],
   "source": [
    "#total columns and count\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb317ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target      1.000000\n",
      "oldpeak     0.438441\n",
      "exang       0.438029\n",
      "cp          0.434854\n",
      "thalach     0.422895\n",
      "ca          0.382085\n",
      "slope       0.345512\n",
      "thal        0.337838\n",
      "sex         0.279501\n",
      "age         0.229324\n",
      "trestbps    0.138772\n",
      "restecg     0.134468\n",
      "chol        0.099966\n",
      "fbs         0.041164\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#check correlation betweem columns\n",
    "print(dataset.corr()[\"target\"].abs().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07cbc403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 717\n",
      "Validation size: 154\n",
      "Test size: 154\n"
     ]
    }
   ],
   "source": [
    "# train test split - 70% train 15% test 15% validation\n",
    "predictors = dataset.drop(\"target\", axis=1)\n",
    "target = dataset[\"target\"]\n",
    "\n",
    "# first - 70% train 30% test\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(\n",
    "    predictors, target,\n",
    "    test_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=target\n",
    ")\n",
    "\n",
    "# second: val and test\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(\n",
    "    X_temp, Y_temp,\n",
    "    test_size=0.50,      # half of 30% = 15%\n",
    "    random_state=42,\n",
    "    stratify=Y_temp\n",
    ")\n",
    "\n",
    "#for confirmation\n",
    "print(\"Train size:\", len(X_train))\n",
    "print(\"Validation size:\", len(X_val))\n",
    "print(\"Test size:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44cf40b",
   "metadata": {},
   "source": [
    "## Training/testing models without GridSearchCV - parent paper results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0622da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Metrics:\n",
      "Accuracy:   80.52 %\n",
      "Precision:  76.34 %\n",
      "Recall:     89.87 %\n",
      "F1 Score:   82.56 %\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# train and predict\n",
    "lr.fit(X_train, Y_train)\n",
    "Y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "# eval metrics\n",
    "accuracy_lr = round(accuracy_score(Y_test, Y_pred_lr) * 100, 2)\n",
    "precision_lr = round(precision_score(Y_test, Y_pred_lr) * 100, 2)\n",
    "recall_lr = round(recall_score(Y_test, Y_pred_lr) * 100, 2)\n",
    "f1_lr = round(f1_score(Y_test, Y_pred_lr) * 100, 2)\n",
    "\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(\"Accuracy:  \", accuracy_lr, \"%\")\n",
    "print(\"Precision: \", precision_lr, \"%\")\n",
    "print(\"Recall:    \", recall_lr, \"%\")\n",
    "print(\"F1 Score:  \", f1_lr, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6037a05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM metrics\n",
      "Accuracy:   85.06 %\n",
      "Precision:  80.43 %\n",
      "Recall:     93.67 %\n",
      "F1 Score:   86.55 %\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "sv = svm.SVC(kernel='linear')\n",
    "\n",
    "# train and test\n",
    "sv.fit(X_train, Y_train)\n",
    "Y_pred_svm = sv.predict(X_test)\n",
    "\n",
    "#eval metrics\n",
    "accuracy_svm = round(accuracy_score(Y_test, Y_pred_svm) * 100, 2)\n",
    "precision_svm = round(precision_score(Y_test, Y_pred_svm) * 100, 2)\n",
    "recall_svm = round(recall_score(Y_test, Y_pred_svm) * 100, 2)\n",
    "f1_svm = round(f1_score(Y_test, Y_pred_svm) * 100, 2)\n",
    "\n",
    "print(\"SVM metrics\")\n",
    "print(\"Accuracy:  \", accuracy_svm, \"%\")\n",
    "print(\"Precision: \", precision_svm, \"%\")\n",
    "print(\"Recall:    \", recall_svm, \"%\")\n",
    "print(\"F1 Score:  \", f1_svm, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "830aa19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN eval\n",
      "Accuracy:   75.97 %\n",
      "Precision:  76.25 %\n",
      "Recall:     77.22 %\n",
      "F1 Score:   76.73 %\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "#train and test\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "#metrics\n",
    "accuracy_knn = round(accuracy_score(Y_test, Y_pred_knn) * 100, 2)\n",
    "precision_knn = round(precision_score(Y_test, Y_pred_knn) * 100, 2)\n",
    "recall_knn = round(recall_score(Y_test, Y_pred_knn) * 100, 2)\n",
    "f1_knn = round(f1_score(Y_test, Y_pred_knn) * 100, 2)\n",
    "\n",
    "print(\"KNN eval\")\n",
    "print(\"Accuracy:  \", accuracy_knn, \"%\")\n",
    "print(\"Precision: \", precision_knn, \"%\")\n",
    "print(\"Recall:    \", recall_knn, \"%\")\n",
    "print(\"F1 Score:  \", f1_knn, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "381cf864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost metrics:\n",
      "Accuracy:   98.05 %\n",
      "Precision:  100.0 %\n",
      "Recall:     96.2 %\n",
      "F1 Score:   98.06 %\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "\n",
    "#train and test\n",
    "xgb_model.fit(X_train, Y_train)\n",
    "Y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# eval metrics\n",
    "accuracy_xgb = round(accuracy_score(Y_test, Y_pred_xgb) * 100, 2)\n",
    "precision_xgb = round(precision_score(Y_test, Y_pred_xgb) * 100, 2)\n",
    "recall_xgb = round(recall_score(Y_test, Y_pred_xgb) * 100, 2)\n",
    "f1_xgb = round(f1_score(Y_test, Y_pred_xgb) * 100, 2)\n",
    "\n",
    "print(\"XGBoost metrics:\")\n",
    "print(\"Accuracy:  \", accuracy_xgb, \"%\")\n",
    "print(\"Precision: \", precision_xgb, \"%\")\n",
    "print(\"Recall:    \", recall_xgb, \"%\")\n",
    "print(\"F1 Score:  \", f1_xgb, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af30227a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest eval:\n",
      "Accuracy:   96.75 %\n",
      "Precision:  100.0 %\n",
      "Recall:     93.67 %\n",
      "F1 Score:   96.73 %\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train and test\n",
    "rf.fit(X_train, Y_train)\n",
    "Y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# eval metrics\n",
    "accuracy_rf = round(accuracy_score(Y_test, Y_pred_rf) * 100, 2)\n",
    "precision_rf = round(precision_score(Y_test, Y_pred_rf) * 100, 2)\n",
    "recall_rf = round(recall_score(Y_test, Y_pred_rf) * 100, 2)\n",
    "f1_rf = round(f1_score(Y_test, Y_pred_rf) * 100, 2)\n",
    "\n",
    "print(\"Random Forest eval:\")\n",
    "print(\"Accuracy:  \", accuracy_rf, \"%\")\n",
    "print(\"Precision: \", precision_rf, \"%\")\n",
    "print(\"Recall:    \", recall_rf, \"%\")\n",
    "print(\"F1 Score:  \", f1_rf, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c34e0723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree eval:\n",
      "Accuracy:   98.05 %\n",
      "Precision:  100.0 %\n",
      "Recall:     96.2 %\n",
      "F1 Score:   98.06 %\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "#train and test\n",
    "dt.fit(X_train, Y_train)\n",
    "Y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "accuracy_dt = round(accuracy_score(Y_test, Y_pred_dt) * 100, 2)\n",
    "precision_dt = round(precision_score(Y_test, Y_pred_dt) * 100, 2)\n",
    "recall_dt = round(recall_score(Y_test, Y_pred_dt) * 100, 2)\n",
    "f1_dt = round(f1_score(Y_test, Y_pred_dt) * 100, 2)\n",
    "\n",
    "print(\"Decision Tree eval:\")\n",
    "print(\"Accuracy:  \", accuracy_dt, \"%\")\n",
    "print(\"Precision: \", precision_dt, \"%\")\n",
    "print(\"Recall:    \", recall_dt, \"%\")\n",
    "print(\"F1 Score:  \", f1_dt, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "472d9618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy (%)  Precision  Recall  F1 Score\n",
      "   Logistic Regression         80.52      76.34   89.87     82.56\n",
      "Support Vector Machine         85.06      80.43   93.67     86.55\n",
      "   K-Nearest Neighbors         75.97      76.25   77.22     76.73\n",
      "               XGBoost         98.05     100.00   96.20     98.06\n",
      "         Random Forest         96.75     100.00   93.67     96.73\n",
      "         Decision Tree         98.05     100.00   96.20     98.06\n"
     ]
    }
   ],
   "source": [
    "#Phase 1 results summary\n",
    "results = {\n",
    "    \"Model\": [\n",
    "        \"Logistic Regression\",\n",
    "        \"Support Vector Machine\",\n",
    "        \"K-Nearest Neighbors\",\n",
    "        \"XGBoost\",\n",
    "        \"Random Forest\",\n",
    "        \"Decision Tree\"\n",
    "    ],\n",
    "    \"Accuracy (%)\": [accuracy_lr, accuracy_svm, accuracy_knn, accuracy_xgb, accuracy_rf, accuracy_dt],\n",
    "    \"Precision\":    [precision_lr, precision_svm, precision_knn, precision_xgb, precision_rf, precision_dt],\n",
    "    \"Recall\":       [recall_lr, recall_svm, recall_knn, recall_xgb, recall_rf, recall_dt],\n",
    "    \"F1 Score\":     [f1_lr, f1_svm, f1_knn, f1_xgb, f1_rf, f1_dt]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7ce8f7",
   "metadata": {},
   "source": [
    "## Training/testing models with GridSearch CV - parent paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f4fb370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n",
      "Logistic Regression eval:\n",
      "Accuracy:  80.52\n",
      "Precision:  76.34\n",
      "Recall:  89.87\n",
      "F1 Score:  82.56\n",
      "Best Params: {'C': 10, 'class_weight': None, 'l1_ratio': 0, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# logistic regresson - grid search\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "params_lr = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'l1_ratio': [0, 0.25, 0.5, 0.75, 1],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "grid_search_lr = GridSearchCV(\n",
    "    estimator=lr,\n",
    "    param_grid=params_lr,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "#train and test\n",
    "grid_search_lr.fit(X_train, Y_train)\n",
    "best_lr = grid_search_lr.best_estimator_\n",
    "Y_pred_lr = best_lr.predict(X_test)\n",
    "\n",
    "#eval metrics\n",
    "accuracy_lr  = round(accuracy_score(Y_test, Y_pred_lr) * 100, 2)\n",
    "precision_lr = round(precision_score(Y_test, Y_pred_lr)* 100, 2)\n",
    "recall_lr = round(recall_score(Y_test, Y_pred_lr) * 100, 2)\n",
    "f1_lr = round(f1_score(Y_test, Y_pred_lr) * 100, 2)\n",
    "\n",
    "print(\"Logistic Regression eval:\")\n",
    "print(\"Accuracy: \", accuracy_lr)\n",
    "print(\"Precision: \", precision_lr)\n",
    "print(\"Recall: \", recall_lr)\n",
    "print(\"F1 Score: \", f1_lr)\n",
    "print(\"Best Params:\", grid_search_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37c5f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Linear SVM Performance (fast GridSearch):\n",
      " Accuracy:   85.71\n",
      " Precision:  0.9014084507042254\n",
      " Recall:     0.810126582278481\n",
      " F1 Score:   0.8533333333333334\n",
      "Best Params: {'C': 10, 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "#svm - grid search\n",
    "svm = svm.SVC(kernel='linear')\n",
    "\n",
    "# smaller grid for faster search\n",
    "params_svm = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(\n",
    "    estimator=sv,\n",
    "    param_grid=params_svm,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# train and test\n",
    "grid_search_svm.fit(X_train, Y_train)\n",
    "best_svm = grid_search_svm.best_estimator_\n",
    "Y_pred_svm = best_svm.predict(X_test)\n",
    "\n",
    "# eval metrics\n",
    "accuracy_svm  = round(accuracy_score(Y_test, Y_pred_svm) * 100, 2)\n",
    "precision_svm = precision_score(Y_test, Y_pred_svm)\n",
    "recall_svm = recall_score(Y_test, Y_pred_svm)\n",
    "f1_svm = f1_score(Y_test, Y_pred_svm)\n",
    "\n",
    "print(\"Linear SVM eval results:\")\n",
    "print(\"Accuracy: \", accuracy_svm)\n",
    "print(\"Precision: \", precision_svm)\n",
    "print(\"Recall: \", recall_svm)\n",
    "print(\"F1 Score: \", f1_svm)\n",
    "print(\"Best Params:\", grid_search_svm.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6209886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Best KNN Parameters: {'metric': 'euclidean', 'n_neighbors': 7, 'p': 1, 'weights': 'distance'}\n",
      "Accuracy: 99.35 %\n",
      "Precision: 100.0 %\n",
      "Recall: 98.73 %\n",
      "F1-Score: 99.36 %\n"
     ]
    }
   ],
   "source": [
    "# knn - grid search\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "params_knn = {\n",
    "    'n_neighbors': [1, 3, 5, 7, 9, 11, 15, 21],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "grid_search_knn = GridSearchCV(\n",
    "    estimator=knn,\n",
    "    param_grid=params_knn,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "#train and test\n",
    "grid_search_knn.fit(X_train, Y_train)\n",
    "best_knn = grid_search_knn.best_estimator_\n",
    "Y_pred_knn = best_knn.predict(X_test)\n",
    "\n",
    "# eval metrics\n",
    "accuracy = round(accuracy_score(Y_test, Y_pred_knn) * 100, 2)\n",
    "precision = round(precision_score(Y_test, Y_pred_knn, average='binary') * 100, 2)\n",
    "recall = round(recall_score(Y_test, Y_pred_knn, average='binary') * 100, 2)\n",
    "f1 = round(f1_score(Y_test, Y_pred_knn, average='binary') * 100, 2)\n",
    "\n",
    "# results\n",
    "print(f\"Best KNN Parameters: {grid_search_knn.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy} %\")\n",
    "print(f\"Precision: {precision} %\")\n",
    "print(f\"Recall: {recall} %\")\n",
    "print(f\"F1-Score: {f1} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8cc771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n",
      "Best XGBoost Parameters: {'colsample_bytree': 1.0, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1.0}\n",
      "Accuracy: 100.0 %\n",
      "Precision: 100.0 %\n",
      "Recall: 100.0 %\n",
      "F1-Score: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "#xgboost - grid search\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "param_grid_fast = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'gamma': [0, 0.1],\n",
    "    'min_child_weight': [1, 3]\n",
    "}\n",
    "\n",
    "grid_search_xgb = GridSearchCV(\n",
    "    estimator=xgb_clf,\n",
    "    param_grid=param_grid_fast,\n",
    "    cv=5,               # 3-fold CV for speed\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# train and test\n",
    "grid_search_xgb.fit(X_train, Y_train)\n",
    "best_xgb = grid_search_xgb.best_estimator_\n",
    "Y_pred_xgb = best_xgb.predict(X_test)\n",
    "\n",
    "# eval metrics\n",
    "accuracy = round(accuracy_score(Y_test, Y_pred_xgb) * 100, 2)\n",
    "precision = round(precision_score(Y_test, Y_pred_xgb, average='binary') * 100, 2)\n",
    "recall = round(recall_score(Y_test, Y_pred_xgb, average='binary') * 100, 2)\n",
    "f1 = round(f1_score(Y_test, Y_pred_xgb, average='binary') * 100, 2)\n",
    "\n",
    "#  results\n",
    "print(f\"Best XGBoost Parameters: {grid_search_xgb.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy} %\")\n",
    "print(f\"Precision: {precision} %\")\n",
    "print(f\"Recall: {recall} %\")\n",
    "print(f\"F1-Score: {f1} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be5c2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n",
      "Best Random Forest Parameters: {'bootstrap': True, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Accuracy: 100.0 %\n",
      "Precision: 100.0 %\n",
      "Recall: 100.0 %\n",
      "F1-Score: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "#random forest - grid search\n",
    "rf_clf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=rf_clf,\n",
    "    param_grid=param_grid_rf,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "#train and test\n",
    "grid_search_rf.fit(X_train, Y_train)\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "Y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "# eval metrics\n",
    "accuracy = round(accuracy_score(Y_test, Y_pred_rf) * 100, 2)\n",
    "precision = round(precision_score(Y_test, Y_pred_rf) * 100, 2)\n",
    "recall = round(recall_score(Y_test, Y_pred_rf) * 100, 2)\n",
    "f1 = round(f1_score(Y_test, Y_pred_rf) * 100, 2)\n",
    "\n",
    "# results\n",
    "print(f\"Best Random Forest Parameters: {grid_search_rf.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy} %\")\n",
    "print(f\"Precision: {precision} %\")\n",
    "print(f\"Recall: {recall} %\")\n",
    "print(f\"F1-Score: {f1} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad83e3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n",
      "Best Decision Tree Parameters: {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Accuracy: 94.81 %\n",
      "Precision: 96.1 %\n",
      "Recall: 93.67 %\n",
      "F1-Score: 94.87 %\n"
     ]
    }
   ],
   "source": [
    "# decision tree -grid search\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "param_grid_dt = {\n",
    "    'max_depth': [None, 3, 5, 7, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4], \n",
    "    'max_features': [None, 'sqrt', 'log2'], \n",
    "    'criterion': ['gini', 'entropy']   \n",
    "}\n",
    "\n",
    "grid_search_dt = GridSearchCV(\n",
    "    estimator=dt_clf,\n",
    "    param_grid=param_grid_dt,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "#train and test\n",
    "grid_search_dt.fit(X_train, Y_train)\n",
    "best_dt = grid_search_dt.best_estimator_\n",
    "Y_pred_dt = best_dt.predict(X_test)\n",
    "\n",
    "# eval metrics\n",
    "accuracy = round(accuracy_score(Y_test, Y_pred_dt) * 100, 2)\n",
    "precision = round(precision_score(Y_test, Y_pred_dt) * 100, 2)\n",
    "recall = round(recall_score(Y_test, Y_pred_dt) * 100, 2)\n",
    "f1 = round(f1_score(Y_test, Y_pred_dt) * 100, 2)\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Decision Tree Parameters: {grid_search_dt.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy} %\")\n",
    "print(f\"Precision: {precision} %\")\n",
    "print(f\"Recall: {recall} %\")\n",
    "print(f\"F1-Score: {f1} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05865cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def pchf(X, n_features=8, n_components=4):\n",
    "    # standardize features to determine variance on same scale\n",
    "    X_scaled = pd.DataFrame(StandardScaler().fit_transform(X), columns=X.columns)\n",
    "    \n",
    "    # calculate variances of each feature and sort to find the top\n",
    "    feature_variances = X_scaled.var().sort_values(ascending=False)\n",
    "    selected_features = feature_variances.head(n_features).index.tolist()\n",
    "    X_top = X_scaled[selected_features].values \n",
    "    \n",
    "    # find covariance matrix and eigen decomposition to find how features relate to each other\n",
    "    cov_matrix = np.cov(X_top, rowvar=False)  # shape: (n_features, n_features)\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "    \n",
    "    # selects most informative and influential components\n",
    "    sorted_idx = np.argsort(eigenvalues)[::-1]\n",
    "    top_eigenvectors = eigenvectors[:, sorted_idx[:n_components]] \n",
    "    \n",
    "    # completes final linear transformation\n",
    "    X_transformed = np.dot(X_top, top_eigenvectors)\n",
    "    \n",
    "    return X_transformed, selected_features, top_eigenvectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c73bd8",
   "metadata": {},
   "source": [
    "## Training models with grid search and pchf feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036adfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Selected Features (PCHF): ['age', 'sex', 'cp', 'exang', 'trestbps', 'chol', 'fbs', 'restecg']\n",
      "Transformation Matrix:\n",
      "[[-0.52551453 -0.10975553  0.08932326  0.1176242 ]\n",
      " [ 0.13309368  0.21390126 -0.69532703 -0.19115739]\n",
      " [ 0.24581068 -0.63826144 -0.08447766 -0.04216228]\n",
      " [-0.30362653  0.58295259 -0.2008337   0.19145052]\n",
      " [-0.44851092 -0.24520462 -0.14946319  0.22930878]\n",
      " [-0.45741475 -0.04924953  0.35090545 -0.24018757]\n",
      " [-0.19617993 -0.32821366 -0.46657595  0.48354396]\n",
      " [ 0.32346826  0.15720548  0.3128962   0.75306381]]\n",
      "Best Logistic Regression Parameters: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Accuracy: 77.27 %\n",
      "Precision: 75.58 %\n",
      "Recall: 82.28 %\n",
      "F1-Score: 78.79 %\n",
      "Confusion Matrix:\n",
      " [[54 21]\n",
      " [14 65]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.72      0.76        75\n",
      "           1       0.76      0.82      0.79        79\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.77      0.77      0.77       154\n",
      "weighted avg       0.77      0.77      0.77       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#logistic regression - grid search and pchf\n",
    "\n",
    "#apply pchf to data\n",
    "X_train_transformed, selected_features, transform_matrix = pchf(\n",
    "    X_train, n_features=8, n_components=4\n",
    ")\n",
    "\n",
    "#scale again\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[selected_features])\n",
    "X_train_transformed = np.dot(X_train_scaled, transform_matrix)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test[selected_features])\n",
    "X_test_transformed = np.dot(X_test_scaled, transform_matrix)\n",
    "\n",
    "#lr\n",
    "logreg = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced'   # handles imbalance (replaces SMOTE)\n",
    ")\n",
    "\n",
    "params_logreg = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']   # supports both l1/l2\n",
    "}\n",
    "\n",
    "grid_search_logreg = GridSearchCV(\n",
    "    estimator=logreg,\n",
    "    param_grid=params_logreg,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "#train and test\n",
    "grid_search_logreg.fit(X_train_transformed, Y_train)\n",
    "best_logreg = grid_search_logreg.best_estimator_\n",
    "Y_pred_logreg = best_logreg.predict(X_test_transformed)\n",
    "\n",
    "accuracy = round(accuracy_score(Y_test, Y_pred_logreg) * 100, 2)\n",
    "precision = round(precision_score(Y_test, Y_pred_logreg) * 100, 2)\n",
    "recall = round(recall_score(Y_test, Y_pred_logreg) * 100, 2)\n",
    "f1 = round(f1_score(Y_test, Y_pred_logreg) * 100, 2)\n",
    "\n",
    "print(f\"Selected Features (PCHF): {selected_features}\")\n",
    "print(f\"Transformation Matrix:\\n{transform_matrix}\")\n",
    "print(f\"Best Logistic Regression Parameters: {grid_search_logreg.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy} %\")\n",
    "print(f\"Precision: {precision} %\")\n",
    "print(f\"Recall: {recall} %\")\n",
    "print(f\"F1-Score: {f1} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fac339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Selected Features (PCHF): ['age', 'sex', 'cp', 'exang', 'trestbps', 'chol', 'fbs', 'restecg']\n",
      "Transformation Matrix:\n",
      "[[-0.52551453 -0.10975553  0.08932326  0.1176242 ]\n",
      " [ 0.13309368  0.21390126 -0.69532703 -0.19115739]\n",
      " [ 0.24581068 -0.63826144 -0.08447766 -0.04216228]\n",
      " [-0.30362653  0.58295259 -0.2008337   0.19145052]\n",
      " [-0.44851092 -0.24520462 -0.14946319  0.22930878]\n",
      " [-0.45741475 -0.04924953  0.35090545 -0.24018757]\n",
      " [-0.19617993 -0.32821366 -0.46657595  0.48354396]\n",
      " [ 0.32346826  0.15720548  0.3128962   0.75306381]]\n",
      "Best SVM Parameters: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Accuracy: 87.66 %\n",
      "Precision: 88.46 %\n",
      "Recall: 87.34 %\n",
      "F1-Score: 87.9 %\n",
      "Confusion Matrix:\n",
      " [[66  9]\n",
      " [10 69]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87        75\n",
      "           1       0.88      0.87      0.88        79\n",
      "\n",
      "    accuracy                           0.88       154\n",
      "   macro avg       0.88      0.88      0.88       154\n",
      "weighted avg       0.88      0.88      0.88       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#svm - grid search and pchf\n",
    "\n",
    "X_train_transformed, selected_features, transform_matrix = pchf(X_train, n_features=8, n_components=4)\n",
    "X_test_transformed = np.dot(StandardScaler().fit_transform(X_test[selected_features]), transform_matrix)\n",
    "\n",
    "# svm\n",
    "svm_model = svm.SVC(random_state=42, class_weight='balanced', probability=True)\n",
    "\n",
    "params_svm = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(\n",
    "    estimator=svm_model,\n",
    "    param_grid=params_svm,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "#train and test\n",
    "grid_search_svm.fit(X_train_transformed, Y_train)\n",
    "best_svm = grid_search_svm.best_estimator_\n",
    "Y_pred_svm = best_svm.predict(X_test_transformed)\n",
    "\n",
    "accuracy = round(accuracy_score(Y_test, Y_pred_svm) * 100, 2)\n",
    "precision = round(precision_score(Y_test, Y_pred_svm) * 100, 2)\n",
    "recall = round(recall_score(Y_test, Y_pred_svm) * 100, 2)\n",
    "f1 = round(f1_score(Y_test, Y_pred_svm) * 100, 2)\n",
    "\n",
    "print(f\"Selected Features (PCHF): {selected_features}\")\n",
    "print(f\"Transformation Matrix:\\n{transform_matrix}\")\n",
    "print(f\"Best SVM Parameters: {grid_search_svm.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy} %\")\n",
    "print(f\"Precision: {precision} %\")\n",
    "print(f\"Recall: {recall} %\")\n",
    "print(f\"F1-Score: {f1} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0214eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Selected Features (PCHF): ['age', 'sex', 'cp', 'exang', 'trestbps', 'chol', 'fbs', 'restecg']\n",
      "Transformation Matrix:\n",
      "[[-0.52551453 -0.10975553  0.08932326  0.1176242 ]\n",
      " [ 0.13309368  0.21390126 -0.69532703 -0.19115739]\n",
      " [ 0.24581068 -0.63826144 -0.08447766 -0.04216228]\n",
      " [-0.30362653  0.58295259 -0.2008337   0.19145052]\n",
      " [-0.44851092 -0.24520462 -0.14946319  0.22930878]\n",
      " [-0.45741475 -0.04924953  0.35090545 -0.24018757]\n",
      " [-0.19617993 -0.32821366 -0.46657595  0.48354396]\n",
      " [ 0.32346826  0.15720548  0.3128962   0.75306381]]\n",
      "Best KNN Parameters: {'metric': 'euclidean', 'n_neighbors': 21, 'p': 1, 'weights': 'distance'}\n",
      "Accuracy: 100.0 %\n",
      "Precision: 100.0 %\n",
      "Recall: 100.0 %\n",
      "F1-Score: 100.0 %\n",
      "Confusion Matrix:\n",
      " [[75  0]\n",
      " [ 0 79]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        75\n",
      "           1       1.00      1.00      1.00        79\n",
      "\n",
      "    accuracy                           1.00       154\n",
      "   macro avg       1.00      1.00      1.00       154\n",
      "weighted avg       1.00      1.00      1.00       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#knn - grid search and pchf\n",
    "X_train_transformed, selected_features, transform_matrix = pchf(X_train, n_features=8, n_components=4)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[selected_features])\n",
    "X_train_transformed = np.dot(X_train_scaled, transform_matrix)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test[selected_features])\n",
    "X_test_transformed = np.dot(X_test_scaled, transform_matrix)\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "params_knn = {\n",
    "    'n_neighbors': [1, 3, 5, 7, 9, 11, 15, 21],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "    'p': [1, 2]  # p=1 (Manhattan), p=2 (Euclidean)\n",
    "}\n",
    "\n",
    "grid_search_knn = GridSearchCV(\n",
    "    estimator=knn_clf,\n",
    "    param_grid=params_knn,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# train and test\n",
    "grid_search_knn.fit(X_train_transformed, Y_train)\n",
    "best_knn = grid_search_knn.best_estimator_\n",
    "Y_pred_knn = best_knn.predict(X_test_transformed)\n",
    "\n",
    "accuracy = round(accuracy_score(Y_test, Y_pred_knn) * 100, 2)\n",
    "precision = round(precision_score(Y_test, Y_pred_knn) * 100, 2)\n",
    "recall = round(recall_score(Y_test, Y_pred_knn) * 100, 2)\n",
    "f1 = round(f1_score(Y_test, Y_pred_knn) * 100, 2)\n",
    "\n",
    "print(f\"Selected Features (PCHF): {selected_features}\")\n",
    "print(f\"Transformation Matrix:\\n{transform_matrix}\")\n",
    "print(f\"Best KNN Parameters: {grid_search_knn.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy} %\")\n",
    "print(f\"Precision: {precision} %\")\n",
    "print(f\"Recall: {recall} %\")\n",
    "print(f\"F1-Score: {f1} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63bdf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n",
      "Selected Features (PCHF): ['age', 'sex', 'cp', 'exang', 'trestbps', 'chol', 'fbs', 'restecg']\n",
      "Transformation Matrix:\n",
      "[[-0.52551453 -0.10975553  0.08932326  0.1176242 ]\n",
      " [ 0.13309368  0.21390126 -0.69532703 -0.19115739]\n",
      " [ 0.24581068 -0.63826144 -0.08447766 -0.04216228]\n",
      " [-0.30362653  0.58295259 -0.2008337   0.19145052]\n",
      " [-0.44851092 -0.24520462 -0.14946319  0.22930878]\n",
      " [-0.45741475 -0.04924953  0.35090545 -0.24018757]\n",
      " [-0.19617993 -0.32821366 -0.46657595  0.48354396]\n",
      " [ 0.32346826  0.15720548  0.3128962   0.75306381]]\n",
      "Best XGBoost Parameters: {'colsample_bytree': 1.0, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Accuracy: 98.05 %\n",
      "Precision: 100.0 %\n",
      "Recall: 96.2 %\n",
      "F1-Score: 98.06 %\n",
      "Confusion Matrix:\n",
      " [[75  0]\n",
      " [ 3 76]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        75\n",
      "           1       1.00      0.96      0.98        79\n",
      "\n",
      "    accuracy                           0.98       154\n",
      "   macro avg       0.98      0.98      0.98       154\n",
      "weighted avg       0.98      0.98      0.98       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#xgboost - grid search and pchf\n",
    "X_train_transformed, selected_features, transform_matrix = pchf(X_train, n_features=8, n_components=4)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[selected_features])\n",
    "X_train_transformed = np.dot(X_train_scaled, transform_matrix)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test[selected_features])\n",
    "X_test_transformed = np.dot(X_test_scaled, transform_matrix)\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "\n",
    "params_xgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'gamma': [0, 0.1],\n",
    "    'min_child_weight': [1, 3]\n",
    "}\n",
    "\n",
    "grid_search_xgb = GridSearchCV(\n",
    "    estimator=xgb_clf,\n",
    "    param_grid=params_xgb,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "#train and test\n",
    "grid_search_xgb.fit(X_train_transformed, Y_train)\n",
    "best_xgb = grid_search_xgb.best_estimator_\n",
    "Y_pred_xgb = best_xgb.predict(X_test_transformed)\n",
    "\n",
    "accuracy = round(accuracy_score(Y_test, Y_pred_xgb) * 100, 2)\n",
    "precision = round(precision_score(Y_test, Y_pred_xgb) * 100, 2)\n",
    "recall = round(recall_score(Y_test, Y_pred_xgb) * 100, 2)\n",
    "f1 = round(f1_score(Y_test, Y_pred_xgb) * 100, 2)\n",
    "\n",
    "print(f\"Selected Features (PCHF): {selected_features}\")\n",
    "print(f\"Transformation Matrix:\\n{transform_matrix}\")\n",
    "print(f\"Best XGBoost Parameters: {grid_search_xgb.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy} %\")\n",
    "print(f\"Precision: {precision} %\")\n",
    "print(f\"Recall: {recall} %\")\n",
    "print(f\"F1-Score: {f1} %\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d46bf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "Selected Features (PCHF): ['age', 'sex', 'cp', 'exang', 'trestbps', 'chol', 'fbs', 'restecg']\n",
      "Transformation Matrix:\n",
      "[[-0.52551453 -0.10975553  0.08932326  0.1176242 ]\n",
      " [ 0.13309368  0.21390126 -0.69532703 -0.19115739]\n",
      " [ 0.24581068 -0.63826144 -0.08447766 -0.04216228]\n",
      " [-0.30362653  0.58295259 -0.2008337   0.19145052]\n",
      " [-0.44851092 -0.24520462 -0.14946319  0.22930878]\n",
      " [-0.45741475 -0.04924953  0.35090545 -0.24018757]\n",
      " [-0.19617993 -0.32821366 -0.46657595  0.48354396]\n",
      " [ 0.32346826  0.15720548  0.3128962   0.75306381]]\n",
      "Best Random Forest Parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "Accuracy: 100.0 %\n",
      "Precision: 100.0 %\n",
      "Recall: 100.0 %\n",
      "F1-Score: 100.0 %\n",
      "Confusion Matrix:\n",
      " [[75  0]\n",
      " [ 0 79]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        75\n",
      "           1       1.00      1.00      1.00        79\n",
      "\n",
      "    accuracy                           1.00       154\n",
      "   macro avg       1.00      1.00      1.00       154\n",
      "weighted avg       1.00      1.00      1.00       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#random forest - grid search and pchf\n",
    "X_train_transformed, selected_features, transform_matrix = pchf(X_train, n_features=8, n_components=4)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[selected_features])\n",
    "X_train_transformed = np.dot(X_train_scaled, transform_matrix)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test[selected_features])\n",
    "X_test_transformed = np.dot(X_test_scaled, transform_matrix)\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "params_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=rf_clf,\n",
    "    param_grid=params_rf,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "#train and test\n",
    "grid_search_rf.fit(X_train_transformed, Y_train)\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "Y_pred_rf = best_rf.predict(X_test_transformed)\n",
    "\n",
    "accuracy = round(accuracy_score(Y_test, Y_pred_rf) * 100, 2)\n",
    "precision = round(precision_score(Y_test, Y_pred_rf) * 100, 2)\n",
    "recall = round(recall_score(Y_test, Y_pred_rf) * 100, 2)\n",
    "f1 = round(f1_score(Y_test, Y_pred_rf) * 100, 2)\n",
    "\n",
    "print(f\"Selected Features (PCHF): {selected_features}\")\n",
    "print(f\"Transformation Matrix:\\n{transform_matrix}\")\n",
    "print(f\"Best Random Forest Parameters: {grid_search_rf.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy} %\")\n",
    "print(f\"Precision: {precision} %\")\n",
    "print(f\"Recall: {recall} %\")\n",
    "print(f\"F1-Score: {f1} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaab934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Selected Features (PCHF): ['age', 'sex', 'cp', 'exang', 'trestbps', 'chol', 'fbs', 'restecg']\n",
      "Transformation Matrix:\n",
      "[[-0.52551453 -0.10975553  0.08932326  0.1176242 ]\n",
      " [ 0.13309368  0.21390126 -0.69532703 -0.19115739]\n",
      " [ 0.24581068 -0.63826144 -0.08447766 -0.04216228]\n",
      " [-0.30362653  0.58295259 -0.2008337   0.19145052]\n",
      " [-0.44851092 -0.24520462 -0.14946319  0.22930878]\n",
      " [-0.45741475 -0.04924953  0.35090545 -0.24018757]\n",
      " [-0.19617993 -0.32821366 -0.46657595  0.48354396]\n",
      " [ 0.32346826  0.15720548  0.3128962   0.75306381]]\n",
      "Best Decision Tree Parameters: {'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Accuracy: 100.0 %\n",
      "Precision: 100.0 %\n",
      "Recall: 100.0 %\n",
      "F1-Score: 100.0 %\n",
      "Confusion Matrix:\n",
      " [[75  0]\n",
      " [ 0 79]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        75\n",
      "           1       1.00      1.00      1.00        79\n",
      "\n",
      "    accuracy                           1.00       154\n",
      "   macro avg       1.00      1.00      1.00       154\n",
      "weighted avg       1.00      1.00      1.00       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#decision tree - grid search and pchf\n",
    "X_train_transformed, selected_features, transform_matrix = pchf(X_train, n_features=8, n_components=4)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[selected_features])\n",
    "X_train_transformed = np.dot(X_train_scaled, transform_matrix)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test[selected_features])\n",
    "X_test_transformed = np.dot(X_test_scaled, transform_matrix)\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "params_dt = {\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_search_dt = GridSearchCV(\n",
    "    estimator=dt_clf,\n",
    "    param_grid=params_dt,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "#train and test\n",
    "grid_search_dt.fit(X_train_transformed, Y_train)\n",
    "best_dt = grid_search_dt.best_estimator_\n",
    "Y_pred_dt = best_dt.predict(X_test_transformed)\n",
    "\n",
    "accuracy = round(accuracy_score(Y_test, Y_pred_dt) * 100, 2)\n",
    "precision = round(precision_score(Y_test, Y_pred_dt) * 100, 2)\n",
    "recall = round(recall_score(Y_test, Y_pred_dt) * 100, 2)\n",
    "f1 = round(f1_score(Y_test, Y_pred_dt) * 100, 2)\n",
    "\n",
    "print(f\"Selected Features (PCHF): {selected_features}\")\n",
    "print(f\"Transformation Matrix:\\n{transform_matrix}\")\n",
    "print(f\"Best Decision Tree Parameters: {grid_search_dt.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy} %\")\n",
    "print(f\"Precision: {precision} %\")\n",
    "print(f\"Recall: {recall} %\")\n",
    "print(f\"F1-Score: {f1} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
