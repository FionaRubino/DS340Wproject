{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2762e9fa",
   "metadata": {},
   "source": [
    "# Heart Disease Prediction - Group 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae6b454e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.vscode', 'dataset-numerical.csv', 'heartprediction.ipynb', 'README.md', 'venv', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "print(os.listdir())\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "407c237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"dataset-numerical.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19081c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1025, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.00000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.434146</td>\n",
       "      <td>0.695610</td>\n",
       "      <td>0.942439</td>\n",
       "      <td>131.611707</td>\n",
       "      <td>246.00000</td>\n",
       "      <td>0.149268</td>\n",
       "      <td>0.529756</td>\n",
       "      <td>149.114146</td>\n",
       "      <td>0.336585</td>\n",
       "      <td>1.071512</td>\n",
       "      <td>1.385366</td>\n",
       "      <td>0.754146</td>\n",
       "      <td>2.323902</td>\n",
       "      <td>0.513171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.072290</td>\n",
       "      <td>0.460373</td>\n",
       "      <td>1.029641</td>\n",
       "      <td>17.516718</td>\n",
       "      <td>51.59251</td>\n",
       "      <td>0.356527</td>\n",
       "      <td>0.527878</td>\n",
       "      <td>23.005724</td>\n",
       "      <td>0.472772</td>\n",
       "      <td>1.175053</td>\n",
       "      <td>0.617755</td>\n",
       "      <td>1.030798</td>\n",
       "      <td>0.620660</td>\n",
       "      <td>0.500070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          sex           cp     trestbps        chol  \\\n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.00000   \n",
       "mean     54.434146     0.695610     0.942439   131.611707   246.00000   \n",
       "std       9.072290     0.460373     1.029641    17.516718    51.59251   \n",
       "min      29.000000     0.000000     0.000000    94.000000   126.00000   \n",
       "25%      48.000000     0.000000     0.000000   120.000000   211.00000   \n",
       "50%      56.000000     1.000000     1.000000   130.000000   240.00000   \n",
       "75%      61.000000     1.000000     2.000000   140.000000   275.00000   \n",
       "max      77.000000     1.000000     3.000000   200.000000   564.00000   \n",
       "\n",
       "               fbs      restecg      thalach        exang      oldpeak  \\\n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.000000   \n",
       "mean      0.149268     0.529756   149.114146     0.336585     1.071512   \n",
       "std       0.356527     0.527878    23.005724     0.472772     1.175053   \n",
       "min       0.000000     0.000000    71.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000   132.000000     0.000000     0.000000   \n",
       "50%       0.000000     1.000000   152.000000     0.000000     0.800000   \n",
       "75%       0.000000     1.000000   166.000000     1.000000     1.800000   \n",
       "max       1.000000     2.000000   202.000000     1.000000     6.200000   \n",
       "\n",
       "             slope           ca         thal       target  \n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  \n",
       "mean      1.385366     0.754146     2.323902     0.513171  \n",
       "std       0.617755     1.030798     0.620660     0.500070  \n",
       "min       0.000000     0.000000     0.000000     0.000000  \n",
       "25%       1.000000     0.000000     2.000000     0.000000  \n",
       "50%       1.000000     0.000000     2.000000     1.000000  \n",
       "75%       2.000000     1.000000     3.000000     1.000000  \n",
       "max       2.000000     4.000000     3.000000     1.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset eda\n",
    "print(dataset.shape)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1dcdc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025 entries, 0 to 1024\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1025 non-null   int64  \n",
      " 1   sex       1025 non-null   int64  \n",
      " 2   cp        1025 non-null   int64  \n",
      " 3   trestbps  1025 non-null   int64  \n",
      " 4   chol      1025 non-null   int64  \n",
      " 5   fbs       1025 non-null   int64  \n",
      " 6   restecg   1025 non-null   int64  \n",
      " 7   thalach   1025 non-null   int64  \n",
      " 8   exang     1025 non-null   int64  \n",
      " 9   oldpeak   1025 non-null   float64\n",
      " 10  slope     1025 non-null   int64  \n",
      " 11  ca        1025 non-null   int64  \n",
      " 12  thal      1025 non-null   int64  \n",
      " 13  target    1025 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 112.2 KB\n"
     ]
    }
   ],
   "source": [
    "#total columns and count\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb317ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target      1.000000\n",
      "oldpeak     0.438441\n",
      "exang       0.438029\n",
      "cp          0.434854\n",
      "thalach     0.422895\n",
      "ca          0.382085\n",
      "slope       0.345512\n",
      "thal        0.337838\n",
      "sex         0.279501\n",
      "age         0.229324\n",
      "trestbps    0.138772\n",
      "restecg     0.134468\n",
      "chol        0.099966\n",
      "fbs         0.041164\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#check correlation betweem columns\n",
    "print(dataset.corr()[\"target\"].abs().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07cbc403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 717\n",
      "Validation size: 154\n",
      "Test size: 154\n"
     ]
    }
   ],
   "source": [
    "# train test split - 70% train 15% test 15% validation\n",
    "predictors = dataset.drop(\"target\", axis=1)\n",
    "target = dataset[\"target\"]\n",
    "\n",
    "# first - 70% train 30% test\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(\n",
    "    predictors, target,\n",
    "    test_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=target\n",
    ")\n",
    "\n",
    "# second: val and test\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(\n",
    "    X_temp, Y_temp,\n",
    "    test_size=0.50,      # half of 30% = 15%\n",
    "    random_state=42,\n",
    "    stratify=Y_temp\n",
    ")\n",
    "\n",
    "#for confirmation\n",
    "print(\"Train size:\", len(X_train))\n",
    "print(\"Validation size:\", len(X_val))\n",
    "print(\"Test size:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44cf40b",
   "metadata": {},
   "source": [
    "## Training/testing models without GridSearchCV - parent paper results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0622da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Metrics:\n",
      "Accuracy:   80.52 %\n",
      "Precision:  76.34 %\n",
      "Recall:     89.87 %\n",
      "F1 Score:   82.56 %\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# train and predict\n",
    "lr.fit(X_train, Y_train)\n",
    "Y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "# eval metrics - rounding for percentage format\n",
    "accuracy_lr = round(accuracy_score(Y_test, Y_pred_lr) * 100, 2)\n",
    "precision_lr = round(precision_score(Y_test, Y_pred_lr) * 100, 2)\n",
    "recall_lr = round(recall_score(Y_test, Y_pred_lr) * 100, 2)\n",
    "f1_lr = round(f1_score(Y_test, Y_pred_lr) * 100, 2)\n",
    "\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(\"Accuracy:  \", accuracy_lr, \"%\")\n",
    "print(\"Precision: \", precision_lr, \"%\")\n",
    "print(\"Recall:    \", recall_lr, \"%\")\n",
    "print(\"F1 Score:  \", f1_lr, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6037a05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM metrics\n",
      "Accuracy:  85.06 %\n",
      "Precision:  80.43 %\n",
      "Recall:  93.67 %\n",
      "F1 Score:  86.55 %\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "sv = svm.SVC(kernel='linear')\n",
    "\n",
    "# train and test\n",
    "sv.fit(X_train, Y_train)\n",
    "Y_pred_svm = sv.predict(X_test)\n",
    "\n",
    "#eval metrics - rounding to format in percentage\n",
    "accuracy_svm = round(accuracy_score(Y_test, Y_pred_svm) * 100, 2)\n",
    "precision_svm = round(precision_score(Y_test, Y_pred_svm) * 100, 2)\n",
    "recall_svm = round(recall_score(Y_test, Y_pred_svm) * 100, 2)\n",
    "f1_svm = round(f1_score(Y_test, Y_pred_svm) * 100, 2)\n",
    "\n",
    "print(\"SVM metrics\")\n",
    "print(\"Accuracy: \", accuracy_svm, \"%\")\n",
    "print(\"Precision: \", precision_svm, \"%\")\n",
    "print(\"Recall: \", recall_svm, \"%\")\n",
    "print(\"F1 Score: \", f1_svm, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "830aa19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN eval\n",
      "Accuracy:  75.97 %\n",
      "Precision:  76.25 %\n",
      "Recall:  77.22 %\n",
      "F1 Score:  76.73 %\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "#train and test\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "#metrics - rounding for percentage format\n",
    "accuracy_knn = round(accuracy_score(Y_test, Y_pred_knn) * 100, 2)\n",
    "precision_knn = round(precision_score(Y_test, Y_pred_knn) * 100, 2)\n",
    "recall_knn = round(recall_score(Y_test, Y_pred_knn) * 100, 2)\n",
    "f1_knn = round(f1_score(Y_test, Y_pred_knn) * 100, 2)\n",
    "\n",
    "print(\"KNN eval\")\n",
    "print(\"Accuracy: \", accuracy_knn, \"%\")\n",
    "print(\"Precision: \", precision_knn, \"%\")\n",
    "print(\"Recall: \", recall_knn, \"%\")\n",
    "print(\"F1 Score: \", f1_knn, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "381cf864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost metrics:\n",
      "Accuracy:  98.05 %\n",
      "Precision:  100.0 %\n",
      "Recall:  96.2 %\n",
      "F1 Score:  98.06 %\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "\n",
    "#train and test\n",
    "xgb_model.fit(X_train, Y_train)\n",
    "Y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# eval metrics - rounding for percentage format\n",
    "accuracy_xgb = round(accuracy_score(Y_test, Y_pred_xgb) * 100, 2)\n",
    "precision_xgb = round(precision_score(Y_test, Y_pred_xgb) * 100, 2)\n",
    "recall_xgb = round(recall_score(Y_test, Y_pred_xgb) * 100, 2)\n",
    "f1_xgb = round(f1_score(Y_test, Y_pred_xgb) * 100, 2)\n",
    "\n",
    "print(\"XGBoost metrics:\")\n",
    "print(\"Accuracy: \", accuracy_xgb, \"%\")\n",
    "print(\"Precision: \", precision_xgb, \"%\")\n",
    "print(\"Recall: \", recall_xgb, \"%\")\n",
    "print(\"F1 Score: \", f1_xgb, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af30227a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest eval:\n",
      "Accuracy:  96.75 %\n",
      "Precision:  100.0 %\n",
      "Recall:  93.67 %\n",
      "F1 Score:  96.73 %\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train and test\n",
    "rf.fit(X_train, Y_train)\n",
    "Y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# eval metrics - rounding for formatting \n",
    "accuracy_rf = round(accuracy_score(Y_test, Y_pred_rf) * 100, 2)\n",
    "precision_rf = round(precision_score(Y_test, Y_pred_rf) * 100, 2)\n",
    "recall_rf = round(recall_score(Y_test, Y_pred_rf) * 100, 2)\n",
    "f1_rf = round(f1_score(Y_test, Y_pred_rf) * 100, 2)\n",
    "\n",
    "print(\"Random Forest eval:\")\n",
    "print(\"Accuracy: \", accuracy_rf, \"%\")\n",
    "print(\"Precision: \", precision_rf, \"%\")\n",
    "print(\"Recall: \", recall_rf, \"%\")\n",
    "print(\"F1 Score: \", f1_rf, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c34e0723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree eval:\n",
      "Accuracy:  98.05 %\n",
      "Precision:  100.0 %\n",
      "Recall:  96.2 %\n",
      "F1 Score:  98.06 %\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "#train and test\n",
    "dt.fit(X_train, Y_train)\n",
    "Y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "# Metrics - rounding for percentage format\n",
    "accuracy_dt = round(accuracy_score(Y_test, Y_pred_dt) * 100, 2)\n",
    "precision_dt = round(precision_score(Y_test, Y_pred_dt) * 100, 2)\n",
    "recall_dt = round(recall_score(Y_test, Y_pred_dt) * 100, 2)\n",
    "f1_dt = round(f1_score(Y_test, Y_pred_dt) * 100, 2)\n",
    "\n",
    "print(\"Decision Tree eval:\")\n",
    "print(\"Accuracy: \", accuracy_dt, \"%\")\n",
    "print(\"Precision: \", precision_dt, \"%\")\n",
    "print(\"Recall: \", recall_dt, \"%\")\n",
    "print(\"F1 Score: \", f1_dt, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "472d9618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy (%)  Precision  Recall  F1 Score\n",
      "   Logistic Regression         80.52      76.34   89.87     82.56\n",
      "Support Vector Machine         85.06      80.43   93.67     86.55\n",
      "   K-Nearest Neighbors         75.97      76.25   77.22     76.73\n",
      "               XGBoost         98.05     100.00   96.20     98.06\n",
      "         Random Forest         96.75     100.00   93.67     96.73\n",
      "         Decision Tree         98.05     100.00   96.20     98.06\n"
     ]
    }
   ],
   "source": [
    "#Phase 1 results summary\n",
    "\n",
    "# dictionary for easy formatting into table\n",
    "results = {\n",
    "    \"Model\": [\n",
    "        \"Logistic Regression\",\n",
    "        \"Support Vector Machine\",\n",
    "        \"K-Nearest Neighbors\",\n",
    "        \"XGBoost\",\n",
    "        \"Random Forest\",\n",
    "        \"Decision Tree\"\n",
    "    ],\n",
    "    \"Accuracy (%)\": [accuracy_lr, accuracy_svm, accuracy_knn, accuracy_xgb, accuracy_rf, accuracy_dt],\n",
    "    \"Precision\":    [precision_lr, precision_svm, precision_knn, precision_xgb, precision_rf, precision_dt],\n",
    "    \"Recall\":       [recall_lr, recall_svm, recall_knn, recall_xgb, recall_rf, recall_dt],\n",
    "    \"F1 Score\":     [f1_lr, f1_svm, f1_knn, f1_xgb, f1_rf, f1_dt]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7ce8f7",
   "metadata": {},
   "source": [
    "## Training/testing models with GridSearch CV - parent paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f4fb370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n",
      "Logistic Regression eval:\n",
      "Accuracy:  80.52\n",
      "Precision:  76.34\n",
      "Recall:  89.87\n",
      "F1 Score:  82.56\n",
      "Best Params: {'C': 10, 'class_weight': None, 'l1_ratio': 0, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# logistic regresson - grid search\n",
    "lr = LogisticRegression(max_iter=1000) # large number for value convergence\n",
    "\n",
    "params_lr = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],  # type of regularization\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # inverse regularization strength\n",
    "    'solver': ['liblinear', 'saga'], # optimization algorithm\n",
    "    'l1_ratio': [0, 0.25, 0.5, 0.75, 1],  # L1/L2 values \n",
    "    'class_weight': [None, 'balanced']   #handle class imbalance\n",
    "}\n",
    "\n",
    "grid_search_lr = GridSearchCV(\n",
    "    estimator=lr,\n",
    "    param_grid=params_lr,\n",
    "    cv=5,\n",
    "    scoring='accuracy', #optimization metric\n",
    "    n_jobs=-1,\n",
    "    verbose=2 # explains progress in gridsearch\n",
    ")\n",
    "\n",
    "#train and test\n",
    "grid_search_lr.fit(X_train, Y_train)\n",
    "best_lr = grid_search_lr.best_estimator_ # tests on best param combination\n",
    "Y_pred_lr = best_lr.predict(X_test)\n",
    "\n",
    "#eval metrics\n",
    "accuracy_lr2  = round(accuracy_score(Y_test, Y_pred_lr) * 100, 2)\n",
    "precision_lr2 = round(precision_score(Y_test, Y_pred_lr)* 100, 2)\n",
    "recall_lr2 = round(recall_score(Y_test, Y_pred_lr) * 100, 2)\n",
    "f1_lr2 = round(f1_score(Y_test, Y_pred_lr) * 100, 2)\n",
    "\n",
    "print(\"Logistic Regression eval:\")\n",
    "print(\"Accuracy: \", accuracy_lr2)\n",
    "print(\"Precision: \", precision_lr2)\n",
    "print(\"Recall: \", recall_lr2)\n",
    "print(\"F1 Score: \", f1_lr2)\n",
    "print(\"Best Params:\", grid_search_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e37c5f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Linear SVM eval results:\n",
      "Accuracy:  85.06\n",
      "Precision:  80.43\n",
      "Recall:  93.67\n",
      "F1 Score:  86.55\n",
      "Best Params: {'C': 1, 'class_weight': None}\n"
     ]
    }
   ],
   "source": [
    "#svm - grid search\n",
    "svmm = svm.SVC(kernel='linear')\n",
    "\n",
    "# smaller grid for faster search\n",
    "params_svm = {\n",
    "    'C': [0.1, 1, 10, 100],  # regularization strength, larger = stricter margin\n",
    "    'class_weight': [None, 'balanced']  #handle for class imbalance\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(\n",
    "    estimator=svmm,\n",
    "    param_grid=params_svm,\n",
    "    cv=5,\n",
    "    scoring='accuracy', #uses accuracy for optimization\n",
    "    n_jobs=-1,\n",
    "    verbose=2 # explains progress\n",
    ")\n",
    "\n",
    "# train and test\n",
    "grid_search_svm.fit(X_train, Y_train)\n",
    "best_svm = grid_search_svm.best_estimator_ # tests on best param combination\n",
    "Y_pred_svm = best_svm.predict(X_test)\n",
    "\n",
    "# eval metrics\n",
    "accuracy_svm2  = round(accuracy_score(Y_test, Y_pred_svm) * 100, 2)\n",
    "precision_svm2 = round(precision_score(Y_test, Y_pred_svm) * 100, 2)\n",
    "recall_svm2 = round(recall_score(Y_test, Y_pred_svm) * 100, 2)\n",
    "f1_svm2 = round(f1_score(Y_test, Y_pred_svm) * 100, 2)\n",
    "\n",
    "print(\"Linear SVM eval results:\")\n",
    "print(\"Accuracy: \", accuracy_svm2)\n",
    "print(\"Precision: \", precision_svm2)\n",
    "print(\"Recall: \", recall_svm2)\n",
    "print(\"F1 Score: \", f1_svm2)\n",
    "print(\"Best Params:\", grid_search_svm.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6209886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Best KNN Parameters: {'metric': 'euclidean', 'n_neighbors': 11, 'p': 1, 'weights': 'distance'}\n",
      "Accuracy: 96.75 %\n",
      "Precision: 100.0 %\n",
      "Recall: 93.67 %\n",
      "F1-Score: 96.73 %\n"
     ]
    }
   ],
   "source": [
    "# knn - grid search\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "params_knn = {\n",
    "    'n_neighbors': [1, 3, 5, 7, 9, 11, 15, 21], # number of nearest neighbors\n",
    "    'weights': ['uniform', 'distance'], # type of weight being used\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'], # type of measurment for distance\n",
    "    'p': [1, 2] \n",
    "}\n",
    "\n",
    "grid_search_knn = GridSearchCV(\n",
    "    estimator=knn,\n",
    "    param_grid=params_knn,\n",
    "    cv=5,\n",
    "    scoring='accuracy', # optimization metric\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "#train and test\n",
    "grid_search_knn.fit(X_train, Y_train)\n",
    "best_knn = grid_search_knn.best_estimator_ # test on best param combinaton\n",
    "Y_pred_knn = best_knn.predict(X_test)\n",
    "\n",
    "# eval metrics\n",
    "accuracy_knn2 = round(accuracy_score(Y_test, Y_pred_knn) * 100, 2)\n",
    "precision_knn2 = round(precision_score(Y_test, Y_pred_knn, average='binary') * 100, 2)\n",
    "recall_knn2 = round(recall_score(Y_test, Y_pred_knn, average='binary') * 100, 2)\n",
    "f1_knn2 = round(f1_score(Y_test, Y_pred_knn, average='binary') * 100, 2)\n",
    "\n",
    "# results\n",
    "print(f\"Best KNN Parameters: {grid_search_knn.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy_knn2} %\")\n",
    "print(f\"Precision: {precision_knn2} %\")\n",
    "print(f\"Recall: {recall_knn2} %\")\n",
    "print(f\"F1-Score: {f1_knn2} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b8cc771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n",
      "Best XGBoost Parameters: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Accuracy: 96.75 %\n",
      "Precision: 97.44 %\n",
      "Recall: 96.2 %\n",
      "F1-Score: 96.82 %\n"
     ]
    }
   ],
   "source": [
    "#xgboost - grid search\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42, # for consistency\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "params_xgb = {\n",
    "    'n_estimators': [100, 200], # number of boosting trees\n",
    "    'max_depth': [3, 5],  # depth of each tree\n",
    "    'learning_rate': [0.05, 0.1],  # step size shrinkage\n",
    "    'subsample': [0.8, 1.0],  # % of samples per tree\n",
    "    'colsample_bytree': [0.8, 1.0], # % of features per tree\n",
    "    'gamma': [0, 0.1],    # min loss reduction for a split\n",
    "    'min_child_weight': [1, 3]   # min sum of instance weights in a leaf\n",
    "}\n",
    "\n",
    "\n",
    "grid_search_xgb = GridSearchCV(\n",
    "    estimator=xgb_clf,\n",
    "    param_grid=params_xgb,\n",
    "    cv=5,\n",
    "    scoring='accuracy', # optimization metric\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# train and test\n",
    "grid_search_xgb.fit(X_train, Y_train)\n",
    "best_xgb = grid_search_xgb.best_estimator_ # uses best param combination\n",
    "Y_pred_xgb = best_xgb.predict(X_test)\n",
    "\n",
    "# eval metrics\n",
    "accuracy_xgb2 = round(accuracy_score(Y_test, Y_pred_xgb) * 100, 2)\n",
    "precision_xgb2 = round(precision_score(Y_test, Y_pred_xgb, average='binary') * 100, 2)\n",
    "recall_xgb2 = round(recall_score(Y_test, Y_pred_xgb, average='binary') * 100, 2)\n",
    "f1_xgb2 = round(f1_score(Y_test, Y_pred_xgb, average='binary') * 100, 2)\n",
    "\n",
    "#  results\n",
    "print(f\"Best XGBoost Parameters: {grid_search_xgb.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy_xgb2} %\")\n",
    "print(f\"Precision: {precision_xgb2} %\")\n",
    "print(f\"Recall: {recall_xgb2} %\")\n",
    "print(f\"F1-Score: {f1_xgb2} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3be5c2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n",
      "Best Random Forest Parameters: {'bootstrap': False, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Accuracy: 96.75 %\n",
      "Precision: 100.0 %\n",
      "Recall: 93.67 %\n",
      "F1-Score: 96.73 %\n"
     ]
    }
   ],
   "source": [
    "#random forest - grid search\n",
    "rf_clf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300, 500], # number of trees\n",
    "    'max_depth': [None, 5, 10, 15],  # max depth of each tree\n",
    "    'min_samples_split': [2, 5, 10],  # min samples to split a node\n",
    "    'min_samples_leaf': [1, 2, 4], # min samples in a leaf\n",
    "    'max_features': ['sqrt', 'log2', None], # features considered per split\n",
    "    'bootstrap': [True, False] # use bootstrapped samples\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=rf_clf,\n",
    "    param_grid=param_grid_rf,\n",
    "    cv=5,\n",
    "    scoring='accuracy', # optimization metric\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "#train and test\n",
    "grid_search_rf.fit(X_train, Y_train)\n",
    "best_rf = grid_search_rf.best_estimator_ # best param combination\n",
    "Y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "# eval metrics\n",
    "accuracy_rf2 = round(accuracy_score(Y_test, Y_pred_rf) * 100, 2)\n",
    "precision_rf2 = round(precision_score(Y_test, Y_pred_rf) * 100, 2)\n",
    "recall_rf2 = round(recall_score(Y_test, Y_pred_rf) * 100, 2)\n",
    "f1_rf2 = round(f1_score(Y_test, Y_pred_rf) * 100, 2)\n",
    "\n",
    "# results\n",
    "print(f\"Best Random Forest Parameters: {grid_search_rf.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy_rf2} %\")\n",
    "print(f\"Precision: {precision_rf2} %\")\n",
    "print(f\"Recall: {recall_rf2} %\")\n",
    "print(f\"F1-Score: {f1_rf2} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad83e3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n",
      "Best Decision Tree Parameters: {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Accuracy: 94.81 %\n",
      "Precision: 96.1 %\n",
      "Recall: 93.67 %\n",
      "F1-Score: 94.87 %\n"
     ]
    }
   ],
   "source": [
    "# decision tree -grid search\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "param_grid_dt = {\n",
    "    'max_depth': [None, 3, 5, 7, 10], # tree depth\n",
    "    'min_samples_split': [2, 5, 10], # min samples to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],  # min samples in a leaf\n",
    "    'max_features': [None, 'sqrt', 'log2'],# features considered per split\n",
    "    'criterion': ['gini', 'entropy']  # impurity measure\n",
    "}\n",
    "\n",
    "\n",
    "grid_search_dt = GridSearchCV(\n",
    "    estimator=dt_clf,\n",
    "    param_grid=param_grid_dt,\n",
    "    cv=5,\n",
    "    scoring='accuracy', # optimization metric\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "#train and test\n",
    "grid_search_dt.fit(X_train, Y_train)\n",
    "best_dt = grid_search_dt.best_estimator_ # best param combination\n",
    "Y_pred_dt = best_dt.predict(X_test)\n",
    "\n",
    "# eval metrics\n",
    "accuracy_dt2 = round(accuracy_score(Y_test, Y_pred_dt) * 100, 2)\n",
    "precision_dt2 = round(precision_score(Y_test, Y_pred_dt) * 100, 2)\n",
    "recall_dt2 = round(recall_score(Y_test, Y_pred_dt) * 100, 2)\n",
    "f1_dt2 = round(f1_score(Y_test, Y_pred_dt) * 100, 2)\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Decision Tree Parameters: {grid_search_dt.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy_dt2} %\")\n",
    "print(f\"Precision: {precision_dt2} %\")\n",
    "print(f\"Recall: {recall_dt2} %\")\n",
    "print(f\"F1-Score: {f1_dt2} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5df9a973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy (%)  Precision  Recall  F1 Score\n",
      "   Logistic Regression         80.52      76.34   89.87     82.56\n",
      "Support Vector Machine         85.06      80.43   93.67     86.55\n",
      "   K-Nearest Neighbors         96.75     100.00   93.67     96.73\n",
      "               XGBoost         96.75      97.44   96.20     96.82\n",
      "         Random Forest         96.75     100.00   93.67     96.73\n",
      "         Decision Tree         94.81      96.10   93.67     94.87\n"
     ]
    }
   ],
   "source": [
    "#Phase 2 results summary\n",
    "\n",
    "# dictionary for easy formatting into table\n",
    "results = {\n",
    "    \"Model\": [\n",
    "        \"Logistic Regression\",\n",
    "        \"Support Vector Machine\",\n",
    "        \"K-Nearest Neighbors\",\n",
    "        \"XGBoost\",\n",
    "        \"Random Forest\",\n",
    "        \"Decision Tree\"\n",
    "    ],\n",
    "    \"Accuracy (%)\": [accuracy_lr2, accuracy_svm2, accuracy_knn2, accuracy_xgb2, accuracy_rf2, accuracy_dt2],\n",
    "    \"Precision\":    [precision_lr2, precision_svm2, precision_knn2, precision_xgb2, precision_rf2, precision_dt2],\n",
    "    \"Recall\":       [recall_lr2, recall_svm2, recall_knn2, recall_xgb2, recall_rf2, recall_dt2],\n",
    "    \"F1 Score\":     [f1_lr2, f1_svm2, f1_knn2, f1_xgb2, f1_rf2, f1_dt2]\n",
    "}\n",
    "\n",
    "results2_df = pd.DataFrame(results)\n",
    "print(results2_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c73bd8",
   "metadata": {},
   "source": [
    "## Training models with grid search and pchf feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b05865cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for implementing PCHF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def pchf(X, n_features=8, n_components=4):\n",
    "    # standardize features to determine variance on same scale - full dataset\n",
    "    X_scaled = pd.DataFrame(StandardScaler().fit_transform(X), columns=X.columns)\n",
    "    \n",
    "    # calculate variances of each feature and sort to find the top\n",
    "    feature_variances = X_scaled.var().sort_values(ascending=False)\n",
    "    selected_features = feature_variances.head(n_features).index.tolist()\n",
    "    X_top = X_scaled[selected_features].values \n",
    "    \n",
    "    # find covariance matrix and eigen decomposition to find how features relate to each other\n",
    "    cov_matrix = np.cov(X_top, rowvar=False)  # shape: (n_features, n_features)\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "    \n",
    "    # selects most informative and influential components\n",
    "    sorted_idx = np.argsort(eigenvalues)[::-1]\n",
    "    top_eigenvectors = eigenvectors[:, sorted_idx[:n_components]] \n",
    "    \n",
    "    # completes final linear transformation\n",
    "    X_transformed = np.dot(X_top, top_eigenvectors) # value mainly for visualization purpose (understand what will happen later)\n",
    "    \n",
    "    return X_transformed, selected_features, top_eigenvectors # X_transformed is discarded later, focus on remainng outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8cfd54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply pchf to data - recieve matrix and feautures for proper scaling\n",
    "X_train_transformed, selected_features, transform_matrix = pchf( X_train, n_features=8, n_components=4\n",
    ")\n",
    "\n",
    "#scale again - for selected feaures\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[selected_features])\n",
    "X_train_transformed = np.dot(X_train_scaled, transform_matrix) # transformation completed with variance assessment and selected features\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test[selected_features])\n",
    "X_test_transformed = np.dot(X_test_scaled, transform_matrix) # same transformation on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "036adfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Selected Features (PCHF): ['cp', 'slope', 'exang', 'restecg', 'fbs', 'ca', 'trestbps', 'sex']\n",
      "Transformation Matrix:\n",
      "[[-0.47311377  0.42565129 -0.14181724  0.23857273]\n",
      " [-0.38417389 -0.09103366 -0.40786762 -0.4491913 ]\n",
      " [ 0.56321783 -0.24161543  0.09620066  0.12826466]\n",
      " [-0.24010265 -0.36585443  0.08991927 -0.31469551]\n",
      " [ 0.18753933  0.51875556 -0.32100403 -0.00580006]\n",
      " [ 0.3740242   0.06888011 -0.33747621 -0.64119103]\n",
      " [ 0.22623174  0.55164845  0.22368756 -0.16847317]\n",
      " [ 0.16572348 -0.20034611 -0.72747641  0.4316044 ]]\n",
      "Best Logistic Regression Parameters: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy: 77.27 %\n",
      "Precision: 76.19 %\n",
      "Recall: 81.01 %\n",
      "F1-Score: 78.53 %\n"
     ]
    }
   ],
   "source": [
    "#logistic regression - grid search and pchf\n",
    "\n",
    "#lr\n",
    "logreg = LogisticRegression(\n",
    "    random_state=42, # for repetition\n",
    "    max_iter=1000, # convergence\n",
    "    class_weight='balanced' # handles imbalance (replaces SMOTE)\n",
    ")\n",
    "\n",
    "params_logreg = {\n",
    "    'C': [0.1, 1, 10, 100], # inverse regularization strength\n",
    "    'penalty': ['l1', 'l2'], # type of regularization\n",
    "    'solver': ['liblinear']  # optimization algorithm for l1 and l2\n",
    "}\n",
    "\n",
    "grid_search_logreg = GridSearchCV(\n",
    "    estimator=logreg,\n",
    "    param_grid=params_logreg,\n",
    "    cv=5,\n",
    "    scoring='accuracy', # optimization metric\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "#train and test\n",
    "grid_search_logreg.fit(X_train_transformed, Y_train) # train on transformed\n",
    "best_logreg = grid_search_logreg.best_estimator_ # best params\n",
    "Y_pred_logreg = best_logreg.predict(X_test_transformed) # test on transformed\n",
    "\n",
    "accuracy_lr3 = round(accuracy_score(Y_test, Y_pred_logreg) * 100, 2)\n",
    "precision_lr3 = round(precision_score(Y_test, Y_pred_logreg) * 100, 2)\n",
    "recall_lr3 = round(recall_score(Y_test, Y_pred_logreg) * 100, 2)\n",
    "f1_lr3 = round(f1_score(Y_test, Y_pred_logreg) * 100, 2)\n",
    "\n",
    "print(f\"Selected Features (PCHF): {selected_features}\")\n",
    "print(f\"Transformation Matrix:\\n{transform_matrix}\")\n",
    "print(f\"Best Logistic Regression Parameters: {grid_search_logreg.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy_lr3} %\")\n",
    "print(f\"Precision: {precision_lr3} %\")\n",
    "print(f\"Recall: {recall_lr3} %\")\n",
    "print(f\"F1-Score: {f1_lr3} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "87fac339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Selected Features (PCHF): ['cp', 'slope', 'exang', 'restecg', 'fbs', 'ca', 'trestbps', 'sex']\n",
      "Transformation Matrix:\n",
      "[[-0.47311377  0.42565129 -0.14181724  0.23857273]\n",
      " [-0.38417389 -0.09103366 -0.40786762 -0.4491913 ]\n",
      " [ 0.56321783 -0.24161543  0.09620066  0.12826466]\n",
      " [-0.24010265 -0.36585443  0.08991927 -0.31469551]\n",
      " [ 0.18753933  0.51875556 -0.32100403 -0.00580006]\n",
      " [ 0.3740242   0.06888011 -0.33747621 -0.64119103]\n",
      " [ 0.22623174  0.55164845  0.22368756 -0.16847317]\n",
      " [ 0.16572348 -0.20034611 -0.72747641  0.4316044 ]]\n",
      "Best SVM Parameters: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Accuracy: 90.91 %\n",
      "Precision: 90.12 %\n",
      "Recall: 92.41 %\n",
      "F1-Score: 91.25 %\n"
     ]
    }
   ],
   "source": [
    "#svm - grid search and pchf\n",
    "svm_model = svm.SVC(random_state=42, class_weight='balanced', probability=True)\n",
    "\n",
    "params_svm = {\n",
    "    'C': [0.1, 1, 10, 100], # regularization strength (larger = stricter margin)\n",
    "    'kernel': ['linear', 'rbf', 'poly'], # type of kernel function\n",
    "    'gamma': ['scale', 'auto'] # kernel coefficients \n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(\n",
    "    estimator=svm_model,\n",
    "    param_grid=params_svm,\n",
    "    cv=5,\n",
    "    scoring='accuracy', # optimization metric\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "#train and test\n",
    "grid_search_svm.fit(X_train_transformed, Y_train) # train on transformed \n",
    "best_svm = grid_search_svm.best_estimator_\n",
    "Y_pred_svm = best_svm.predict(X_test_transformed) # test on transformed\n",
    "\n",
    "accuracy_svm3 = round(accuracy_score(Y_test, Y_pred_svm) * 100, 2)\n",
    "precision_svm3 = round(precision_score(Y_test, Y_pred_svm) * 100, 2)\n",
    "recall_svm3 = round(recall_score(Y_test, Y_pred_svm) * 100, 2)\n",
    "f1_svm3 = round(f1_score(Y_test, Y_pred_svm) * 100, 2)\n",
    "\n",
    "print(f\"Selected Features (PCHF): {selected_features}\")\n",
    "print(f\"Transformation Matrix:\\n{transform_matrix}\")\n",
    "print(f\"Best SVM Parameters: {grid_search_svm.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy_svm3} %\")\n",
    "print(f\"Precision: {precision_svm3} %\")\n",
    "print(f\"Recall: {recall_svm3} %\")\n",
    "print(f\"F1-Score: {f1_svm3} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b0214eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Selected Features (PCHF): ['cp', 'slope', 'exang', 'restecg', 'fbs', 'ca', 'trestbps', 'sex']\n",
      "Transformation Matrix:\n",
      "[[-0.47311377  0.42565129 -0.14181724  0.23857273]\n",
      " [-0.38417389 -0.09103366 -0.40786762 -0.4491913 ]\n",
      " [ 0.56321783 -0.24161543  0.09620066  0.12826466]\n",
      " [-0.24010265 -0.36585443  0.08991927 -0.31469551]\n",
      " [ 0.18753933  0.51875556 -0.32100403 -0.00580006]\n",
      " [ 0.3740242   0.06888011 -0.33747621 -0.64119103]\n",
      " [ 0.22623174  0.55164845  0.22368756 -0.16847317]\n",
      " [ 0.16572348 -0.20034611 -0.72747641  0.4316044 ]]\n",
      "Best KNN Parameters: {'metric': 'euclidean', 'n_neighbors': 21, 'p': 1, 'weights': 'distance'}\n",
      "Accuracy: 98.05 %\n",
      "Precision: 100.0 %\n",
      "Recall: 96.2 %\n",
      "F1-Score: 98.06 %\n"
     ]
    }
   ],
   "source": [
    "#knn - grid search and pchf\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "params_knn = {\n",
    "    'n_neighbors': [1, 3, 5, 7, 9, 11, 15, 21], # number of nearest neighbors\n",
    "    'weights': ['uniform', 'distance'], # weighted calc\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'], # distance calculation\n",
    "    'p': [1, 2]  # p=1 - Manhattan, p=2 - Euclidean\n",
    "}\n",
    "\n",
    "grid_search_knn = GridSearchCV(\n",
    "    estimator=knn_clf,\n",
    "    param_grid=params_knn,\n",
    "    cv=5,\n",
    "    scoring='accuracy', # optimization metric\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# train and test\n",
    "grid_search_knn.fit(X_train_transformed, Y_train) # train on tranformed\n",
    "best_knn = grid_search_knn.best_estimator_ \n",
    "Y_pred_knn = best_knn.predict(X_test_transformed) # test on transformed\n",
    "\n",
    "accuracy_knn3 = round(accuracy_score(Y_test, Y_pred_knn) * 100, 2)\n",
    "precision_knn3 = round(precision_score(Y_test, Y_pred_knn) * 100, 2)\n",
    "recall_knn3 = round(recall_score(Y_test, Y_pred_knn) * 100, 2)\n",
    "f1_knn3 = round(f1_score(Y_test, Y_pred_knn) * 100, 2)\n",
    "\n",
    "print(f\"Selected Features (PCHF): {selected_features}\")\n",
    "print(f\"Transformation Matrix:\\n{transform_matrix}\")\n",
    "print(f\"Best KNN Parameters: {grid_search_knn.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy_knn3} %\")\n",
    "print(f\"Precision: {precision_knn3} %\")\n",
    "print(f\"Recall: {recall_knn3} %\")\n",
    "print(f\"F1-Score: {f1_knn3} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e63bdf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n",
      "Selected Features (PCHF): ['cp', 'slope', 'exang', 'restecg', 'fbs', 'ca', 'trestbps', 'sex']\n",
      "Transformation Matrix:\n",
      "[[-0.47311377  0.42565129 -0.14181724  0.23857273]\n",
      " [-0.38417389 -0.09103366 -0.40786762 -0.4491913 ]\n",
      " [ 0.56321783 -0.24161543  0.09620066  0.12826466]\n",
      " [-0.24010265 -0.36585443  0.08991927 -0.31469551]\n",
      " [ 0.18753933  0.51875556 -0.32100403 -0.00580006]\n",
      " [ 0.3740242   0.06888011 -0.33747621 -0.64119103]\n",
      " [ 0.22623174  0.55164845  0.22368756 -0.16847317]\n",
      " [ 0.16572348 -0.20034611 -0.72747641  0.4316044 ]]\n",
      "Best XGBoost Parameters: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Accuracy: 98.05 %\n",
      "Precision: 100.0 %\n",
      "Recall: 96.2 %\n",
      "F1-Score: 98.06 %\n"
     ]
    }
   ],
   "source": [
    "#xgboost - grid search and pchf\n",
    "xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "\n",
    "params_xgb = {\n",
    "    'n_estimators': [100, 200], # number of boosting trees\n",
    "    'max_depth': [3, 5],   # max depth of each tree\n",
    "    'learning_rate': [0.05, 0.1], # step size shrinkage for weight updates\n",
    "    'subsample': [0.8, 1.0],   # fraction of samples used per tree\n",
    "    'colsample_bytree': [0.8, 1.0],  # fraction of features used per tree\n",
    "    'gamma': [0, 0.1], # min loss reduction required to split\n",
    "    'min_child_weight': [1, 3]  # min sum of instance weights in a child\n",
    "}\n",
    "\n",
    "grid_search_xgb = GridSearchCV(\n",
    "    estimator=xgb_clf,\n",
    "    param_grid=params_xgb,\n",
    "    cv=5,\n",
    "    scoring='accuracy', # optimized metrix\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "#train and test\n",
    "grid_search_xgb.fit(X_train_transformed, Y_train) # train on transformed data\n",
    "best_xgb = grid_search_xgb.best_estimator_\n",
    "Y_pred_xgb = best_xgb.predict(X_test_transformed) # test on transformed data\n",
    "\n",
    "accuracy_xgb3 = round(accuracy_score(Y_test, Y_pred_xgb) * 100, 2)\n",
    "precision_xgb3 = round(precision_score(Y_test, Y_pred_xgb) * 100, 2)\n",
    "recall_xgb3 = round(recall_score(Y_test, Y_pred_xgb) * 100, 2)\n",
    "f1_xgb3 = round(f1_score(Y_test, Y_pred_xgb) * 100, 2)\n",
    "\n",
    "print(f\"Selected Features (PCHF): {selected_features}\")\n",
    "print(f\"Transformation Matrix:\\n{transform_matrix}\")\n",
    "print(f\"Best XGBoost Parameters: {grid_search_xgb.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy_xgb3} %\")\n",
    "print(f\"Precision: {precision_xgb3} %\")\n",
    "print(f\"Recall: {recall_xgb3} %\")\n",
    "print(f\"F1-Score: {f1_xgb3} %\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d46bf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "Selected Features (PCHF): ['cp', 'slope', 'exang', 'restecg', 'fbs', 'ca', 'trestbps', 'sex']\n",
      "Transformation Matrix:\n",
      "[[-0.47311377  0.42565129 -0.14181724  0.23857273]\n",
      " [-0.38417389 -0.09103366 -0.40786762 -0.4491913 ]\n",
      " [ 0.56321783 -0.24161543  0.09620066  0.12826466]\n",
      " [-0.24010265 -0.36585443  0.08991927 -0.31469551]\n",
      " [ 0.18753933  0.51875556 -0.32100403 -0.00580006]\n",
      " [ 0.3740242   0.06888011 -0.33747621 -0.64119103]\n",
      " [ 0.22623174  0.55164845  0.22368756 -0.16847317]\n",
      " [ 0.16572348 -0.20034611 -0.72747641  0.4316044 ]]\n",
      "Best Random Forest Parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "Accuracy: 98.05 %\n",
      "Precision: 100.0 %\n",
      "Recall: 96.2 %\n",
      "F1-Score: 98.06 %\n"
     ]
    }
   ],
   "source": [
    "#random forest - grid search and pchf\n",
    "rf_clf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "params_rf = {\n",
    "    'n_estimators': [100, 200, 300], # num trees in forest\n",
    "    'max_depth': [None, 5, 10, 15], # max depth of tree\n",
    "    'min_samples_split': [2, 5, 10], # min samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4], # min samples required at a leaf node\n",
    "    'max_features': ['sqrt', 'log2', None]  # num features considered for each split\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=rf_clf,\n",
    "    param_grid=params_rf,\n",
    "    cv=5,\n",
    "    scoring='accuracy', # optimization metric\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "#train and test\n",
    "grid_search_rf.fit(X_train_transformed, Y_train) # training on transformed data\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "Y_pred_rf = best_rf.predict(X_test_transformed) # test on transformed \n",
    "\n",
    "accuracy_rf3 = round(accuracy_score(Y_test, Y_pred_rf) * 100, 2)\n",
    "precision_rf3 = round(precision_score(Y_test, Y_pred_rf) * 100, 2)\n",
    "recall_rf3 = round(recall_score(Y_test, Y_pred_rf) * 100, 2)\n",
    "f1_rf3 = round(f1_score(Y_test, Y_pred_rf) * 100, 2)\n",
    "\n",
    "print(f\"Selected Features (PCHF): {selected_features}\")\n",
    "print(f\"Transformation Matrix:\\n{transform_matrix}\")\n",
    "print(f\"Best Random Forest Parameters: {grid_search_rf.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy_rf3} %\")\n",
    "print(f\"Precision: {precision_rf3} %\")\n",
    "print(f\"Recall: {recall_rf3} %\")\n",
    "print(f\"F1-Score: {f1_rf3} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1aaab934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Selected Features (PCHF): ['cp', 'slope', 'exang', 'restecg', 'fbs', 'ca', 'trestbps', 'sex']\n",
      "Transformation Matrix:\n",
      "[[-0.47311377  0.42565129 -0.14181724  0.23857273]\n",
      " [-0.38417389 -0.09103366 -0.40786762 -0.4491913 ]\n",
      " [ 0.56321783 -0.24161543  0.09620066  0.12826466]\n",
      " [-0.24010265 -0.36585443  0.08991927 -0.31469551]\n",
      " [ 0.18753933  0.51875556 -0.32100403 -0.00580006]\n",
      " [ 0.3740242   0.06888011 -0.33747621 -0.64119103]\n",
      " [ 0.22623174  0.55164845  0.22368756 -0.16847317]\n",
      " [ 0.16572348 -0.20034611 -0.72747641  0.4316044 ]]\n",
      "Best Decision Tree Parameters: {'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Accuracy: 98.05 %\n",
      "Precision: 100.0 %\n",
      "Recall: 96.2 %\n",
      "F1-Score: 98.06 %\n"
     ]
    }
   ],
   "source": [
    "#decision tree - grid search and pchf\n",
    "dt_clf = DecisionTreeClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "params_dt = {\n",
    "    'max_depth': [None, 5, 10, 15], # max depth of tree\n",
    "    'min_samples_split': [2, 5, 10],  # min samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],  # min samples required at a leaf node\n",
    "    'max_features': [None, 'sqrt', 'log2'], # num features considered for each split\n",
    "    'criterion': ['gini', 'entropy']  # function to measure split quality\n",
    "}\n",
    "\n",
    "\n",
    "grid_search_dt = GridSearchCV(\n",
    "    estimator=dt_clf,\n",
    "    param_grid=params_dt,\n",
    "    cv=5,\n",
    "    scoring='accuracy', # optimization metric\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "#train and test\n",
    "grid_search_dt.fit(X_train_transformed, Y_train) # train on transformed\n",
    "best_dt = grid_search_dt.best_estimator_\n",
    "Y_pred_dt = best_dt.predict(X_test_transformed) # test on transformed\n",
    "\n",
    "accuracy_dt3 = round(accuracy_score(Y_test, Y_pred_dt) * 100, 2)\n",
    "precision_dt3 = round(precision_score(Y_test, Y_pred_dt) * 100, 2)\n",
    "recall_dt3 = round(recall_score(Y_test, Y_pred_dt) * 100, 2)\n",
    "f1_dt3 = round(f1_score(Y_test, Y_pred_dt) * 100, 2)\n",
    "\n",
    "print(f\"Selected Features (PCHF): {selected_features}\")\n",
    "print(f\"Transformation Matrix:\\n{transform_matrix}\")\n",
    "print(f\"Best Decision Tree Parameters: {grid_search_dt.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy_dt3} %\")\n",
    "print(f\"Precision: {precision_dt3} %\")\n",
    "print(f\"Recall: {recall_dt3} %\")\n",
    "print(f\"F1-Score: {f1_dt3} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8fa2241f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy (%)  Precision  Recall  F1 Score\n",
      "   Logistic Regression         77.27      76.19   81.01     78.53\n",
      "Support Vector Machine         90.91      90.12   92.41     91.25\n",
      "   K-Nearest Neighbors         98.05     100.00   96.20     98.06\n",
      "               XGBoost         98.05     100.00   96.20     98.06\n",
      "         Random Forest         98.05     100.00   96.20     98.06\n",
      "         Decision Tree         98.05     100.00   96.20     98.06\n"
     ]
    }
   ],
   "source": [
    "#Phase 3 results summary\n",
    "\n",
    "# dictionary for easy formatting into table\n",
    "results3 = {\n",
    "    \"Model\": [\n",
    "        \"Logistic Regression\",\n",
    "        \"Support Vector Machine\",\n",
    "        \"K-Nearest Neighbors\",\n",
    "        \"XGBoost\",\n",
    "        \"Random Forest\",\n",
    "        \"Decision Tree\"\n",
    "    ],\n",
    "    \"Accuracy (%)\": [accuracy_lr3, accuracy_svm3, accuracy_knn3, accuracy_xgb3, accuracy_rf3, accuracy_dt3],\n",
    "    \"Precision\":    [precision_lr3, precision_svm3, precision_knn3, precision_xgb3, precision_rf3, precision_dt3],\n",
    "    \"Recall\":       [recall_lr3, recall_svm3, recall_knn3, recall_xgb3, recall_rf3, recall_dt3],\n",
    "    \"F1 Score\":     [f1_lr3, f1_svm3, f1_knn3, f1_xgb3, f1_rf3, f1_dt3]\n",
    "}\n",
    "\n",
    "results3_df = pd.DataFrame(results3)\n",
    "print(results3_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
